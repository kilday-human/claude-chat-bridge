# Claudeâ€“GPT Bridge ğŸ”—ğŸ¤–

**AI-to-AI conversation framework.**  
Seamlessly route prompts between **OpenAI GPT (including GPT-5)** and **Anthropic Claude**, with cost logging, mock testing, and router heuristics.

---

## âœ¨ Highlights
- ğŸ”„ **Bridge Conversations**: GPT â†” Claude in sequential or parallel modes  
- ğŸ’¸ **Cost Ledger**: Tracks token usage + $ across runs  
- ğŸ§ª **Mock Mode**: Safe, offline testing with stub responses  
- ğŸš¦ **Router**: Heuristic routing (cheap vs strong model) built in  
- âš¡ **CLI First**: Simple one-liner commands for devs  

---

## ğŸš€ Quick Start
```bash
git clone https://github.com/kilday-human/claude-chat-bridge.git
cd claude-chat-bridge
python3 -m venv bridge-env && source bridge-env/bin/activate
pip install -r requirements.txt

# Run your first bridged conversation:
python3 cli_bridge.py "Hello world" --router
ğŸ‘‰ Dive into full usage & docs â†“ for advanced commands, testing, and model configs.

# Claude Chat Bridge

A Python CLI tool that bridges conversations between OpenAI's GPT models (including GPT-5) and Anthropic's Claude models, enabling AI-to-AI conversations and comparisons.

## ğŸš€ Features

- **GPT-5 Support**: Full compatibility with OpenAI's new Responses API  
- **Claude Opus 4**: Support for Anthropic's latest Claude models  
- **Dual Execution Modes**: Run models in parallel or sequential mode  
- **Router Mode**: Route prompts between cheap and strong models with cost logging  
- **Mock Mode**: Test without API calls using built-in mock responses  
- **Conversation Bridging**: Seamlessly pass conversations between models  
- **Robust Error Handling**: Graceful handling of API limits and edge cases  
- **Comprehensive Testing**: Built-in test suite for reliability  

## ğŸ“‹ Requirements

- Python 3.13+  
- OpenAI API key (for GPT models)  
- Anthropic API key (for Claude models)  

## ğŸ› ï¸ Installation

```bash
git clone <repository-url>
cd claude-chat-bridge
python3 -m venv bridge-env
source bridge-env/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
Set API keys in .env or export directly:

bash
Copy
Edit
export OPENAI_API_KEY="sk-your-openai-key"
export ANTHROPIC_API_KEY="sk-ant-your-anthropic-key"
ğŸ”§ Usage
Basic Examples
Single turn conversation:

bash
Copy
Edit
python3 cli_bridge.py "Explain quantum computing in one sentence." 1
Multi-turn conversation:

bash
Copy
Edit
python3 cli_bridge.py "Write a haiku about AI, then explain it." 3
Router mode (cheap â†’ strong with cost logs):

bash
Copy
Edit
python3 cli_bridge.py "hello again" --router
Mock mode (no API calls):

bash
Copy
Edit
python3 cli_bridge.py "Hello world!" 1 --mock
Parallel execution:

bash
Copy
Edit
python3 cli_bridge.py "Compare Python and JavaScript." 1 --parallel
Command Line Options
bash
Copy
Edit
python3 cli_bridge.py <prompt> <turns> [options]
Arguments:

prompt: The initial prompt to send to both models

turns: Number of conversation turns to execute

Options:

--mock â†’ run in mock mode (no external API calls)

--parallel â†’ run models in parallel

--no-parallel â†’ force sequential execution (default)

--router â†’ use routing + cost ledger

--max-tokens N â†’ set max tokens per response (default: 512)

--log-cost â†’ log token usage and costs

--ensure-output â†’ ensure models produce output

ğŸ“ Project Structure
pgsql
Copy
Edit
claude-chat-bridge/
â”œâ”€â”€ cli_bridge.py          # Main CLI entrypoint
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ router.py          # Routing logic
â”‚   â”œâ”€â”€ cost_ledger.py     # Token + cost logging
â”‚   â”œâ”€â”€ bridge.py          # Core bridge loop
â”‚   â””â”€â”€ wrappers/
â”‚       â”œâ”€â”€ chatgpt_wrapper.py  # OpenAI API wrapper
â”‚       â””â”€â”€ claude_wrapper.py   # Anthropic API wrapper
â”œâ”€â”€ test_bridge.py         # Test suite
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ cost_ledger.jsonl  # Cost logs
â””â”€â”€ README.md
ğŸ”„ How It Works
Conversation Initiation â†’ send initial prompt to GPT + Claude

Response Exchange â†’ each modelâ€™s output becomes input for the other

Conversation Flow â†’ continue for N turns

Router â†’ decides whether cheap or strong model should handle

Cost Ledger â†’ logs tokens + $$ usage to logs/cost_ledger.jsonl

Output â†’ responses printed to console

ğŸ§ª Testing
Run the full suite:

bash
Copy
Edit
python3 test_bridge.py
Check syntax only:

bash
Copy
Edit
python3 -m py_compile src/*.py cli_bridge.py
Quick mock tests:

bash
Copy
Edit
python3 cli_bridge.py "Reply 'bridge-ok' only." 1 --mock
ğŸ› Troubleshooting
SyntaxError: from future â†’ must be very first line of file

No cost logs â†’ ensure --router is used and logs/ exists

API key errors â†’ verify .env values and install python-dotenv

Token errors â†’ increase --max-tokens (e.g. 1024, 2048)

ğŸ“œ License
MIT License

ğŸ”— API Docs
OpenAI API

Anthropic API

Status: âœ… MVP functional with router + cost ledger
Last Updated: August 21, 2025

## ğŸ›  Using Makefile

For convenience, a `Makefile` is included with common tasks:

```bash
# Create virtual environment and install dependencies
make venv

# Show how to activate the environment
make activate

# Run tests
make test

# Quick mock demo (no API calls)
make run

# Real run (API calls with router enabled)
make live


## ğŸ›  Using Makefile

For convenience, a `Makefile` is included with common tasks:

\`\`\`bash
# Create virtual environment and install dependencies
make venv

# Show how to activate the environment
make activate

# Run tests
make test

# Quick mock demo (no API calls)
make run

# Real run (API calls with router enabled)
make live
\`\`\`


## ğŸ›  Using Makefile

For convenience, a `Makefile` is included with common tasks:

\`\`\`bash
# Create virtual environment and install dependencies
make venv

# Show how to activate the environment
make activate

# Run tests
make test

# Quick mock demo (no API calls)
make run

# Real run (API calls with router enabled)
make live
\`\`\`

