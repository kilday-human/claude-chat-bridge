# Claude â†” ChatGPT Bridge

*A production-ready AI bridge enabling seamless conversations between Anthropic Claude and OpenAI ChatGPT with comprehensive error handling, retry logic, and dual interfaces.*

## ğŸ¯ Project Overview

**Development Timeline**: 8+ weeks (May 2025 - July 2025)  
**Architecture**: Full-stack AI integration with CLI and web interfaces  
**Testing**: 9/9 comprehensive test suite with CI/CD integration  

This project demonstrates enterprise-level AI system integration with robust error handling, production deployment readiness, and professional user experience design.

## âœ¨ Key Features

### ğŸ”§ **Production Engineering**
- **Exponential backoff retry logic** with Fibonacci jitter
- **Comprehensive error handling** for API failures and rate limits
- **Graceful degradation** when services are overloaded
- **Environment-based configuration** with secure secrets management
- **GitHub Actions CI/CD** with automated testing and linting

### ğŸ¤– **AI Integration**
- **Dual API support** for Claude (Anthropic) and ChatGPT (OpenAI)
- **Intelligent conversation bridging** with multi-turn support
- **Response comparison and analysis** with keyword-based evaluation
- **Token usage tracking** and cost optimization
- **Model flexibility** with configurable endpoints

### ğŸ¨ **User Experience**
- **Streamlit web interface** with real-time side-by-side comparison
- **CLI tool** for programmatic access and automation
- **Loading states and progress indicators** for async operations
- **Helpful error messages** with recovery suggestions
- **API status monitoring** and configuration validation

## ğŸš€ Quick Start

```bash
# Clone and setup
git clone https://github.com/kilday-human/claude-chat-bridge.git
cd claude-chat-bridge
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Configure API keys
cp .env.example .env
# Edit .env with your actual API keys

# Test with mock responses (no API calls)
python cli_bridge.py "Compare AI safety approaches" 2 --mock

# Launch web interface
streamlit run bridge.py
```

## ğŸ—ï¸ Architecture

### **Project Structure**
```
claude-chat-bridge/
â”œâ”€â”€ ğŸ¯ Core Bridge
â”‚   â”œâ”€â”€ cli_bridge.py          # CLI interface with conversation management
â”‚   â”œâ”€â”€ bridge.py              # Streamlit web application
â”‚   â””â”€â”€ backoff_utils.py       # Fibonacci jitter retry logic
â”œâ”€â”€ ğŸ”Œ API Wrappers
â”‚   â”œâ”€â”€ claude_wrapper.py      # Anthropic Claude integration
â”‚   â”œâ”€â”€ chatgpt_wrapper.py     # OpenAI ChatGPT integration
â”‚   â””â”€â”€ metrics.py             # Response analysis and comparison
â”œâ”€â”€ ğŸ§ª Testing Infrastructure
â”‚   â”œâ”€â”€ tests/                 # Comprehensive test suite (9 tests)
â”‚   â”œâ”€â”€ .github/workflows/     # CI/CD automation
â”‚   â””â”€â”€ requirements.txt       # Dependency management
â””â”€â”€ ğŸ“š Documentation
    â”œâ”€â”€ README.md              # This file
    â””â”€â”€ .env.example           # Configuration template
```

### **Technical Stack**
- **Languages**: Python 3.13+
- **AI APIs**: Anthropic Claude, OpenAI GPT
- **Web Framework**: Streamlit
- **Testing**: pytest with comprehensive coverage
- **CI/CD**: GitHub Actions
- **Infrastructure**: Environment-based config, Docker-ready

## ğŸ’» Usage Examples

### **CLI Mode**
```bash
# Multi-turn conversation bridge
python cli_bridge.py "Explain quantum computing" 3

# Mock mode for testing (no API costs)
python cli_bridge.py "Write a haiku about AI" 1 --mock
```

### **Web Interface**
```bash
streamlit run bridge.py
```
- Enter prompts in the web interface
- Compare responses side-by-side
- Analyze differences with keyword highlighting
- Graceful error handling for API failures

### **Programmatic Usage**
```python
from claude_wrapper import send_to_claude
from chatgpt_wrapper import send_to_chatgpt

messages = [{"role": "user", "content": "Hello!"}]
claude_response = send_to_claude(messages)
gpt_response = send_to_chatgpt(messages)
```

## ğŸ§ª Testing & Quality Assurance

```bash
# Run comprehensive test suite
pytest -v

# All 9 tests covering:
# âœ… API wrapper functionality
# âœ… Conversation bridge logic  
# âœ… Error handling and retry mechanisms
# âœ… Latency monitoring and metrics
# âœ… Backoff utility functions
```

**Test Coverage Areas**:
- Basic wrapper functionality for both APIs
- Multi-turn conversation handling
- Error scenarios and retry logic
- Rate limiting and overload conditions
- Metrics and response analysis

## ğŸ”’ Security & Configuration

### **Environment Variables**
```bash
# Required API keys
OPENAI_API_KEY=your-openai-api-key-here
CLAUDE_API_KEY=your-anthropic-api-key-here
```

### **Security Features**
- âœ… Environment variable-based secrets management
- âœ… API key validation and sanitization
- âœ… Secure headers and request handling
- âœ… No hardcoded credentials in codebase
- âœ… .gitignore protection for sensitive files

## ğŸ›ï¸ Advanced Features

### **Error Handling & Resilience**
- **Automatic retries** with exponential backoff
- **Overload detection** and graceful fallback
- **Rate limit awareness** with intelligent delays
- **Timeout handling** and connection management
- **Detailed logging** for debugging and monitoring

### **Response Analysis**
- **Coverage comparison** between AI models
- **Length parity analysis** for response balance
- **Safety filtering** for content validation
- **Keyword-based evaluation** for targeted analysis
- **JSON metrics export** for further processing

## ğŸš€ Deployment Ready

### **Production Features**
- **Environment-based configuration** for different deployment stages
- **Comprehensive error handling** for production stability
- **Monitoring and logging** capabilities
- **Resource optimization** with connection pooling
- **Scalable architecture** supporting multiple concurrent users

### **CI/CD Pipeline**
- **Automated testing** on every commit
- **Code quality checks** with linting
- **Dependency scanning** for security
- **Multi-environment support** (dev/staging/prod)

## ğŸ”„ Recent Updates

- **v2.1** (July 2025): Added robust Streamlit interface with retry logic
- **v2.0** (July 2025): Comprehensive error handling and production polish
- **v1.5** (June 2025): Enhanced testing suite and CI/CD integration
- **v1.0** (May 2025): Initial release with core bridge functionality

## ğŸ“ˆ Engineering Highlights

This project showcases **senior-level engineering practices**:

- **8+ week sustained development** demonstrating project ownership
- **Production engineering mindset** with comprehensive error handling
- **Full-stack capabilities** from CLI tools to web interfaces
- **API integration expertise** with multiple external services
- **Testing discipline** with comprehensive coverage
- **User experience focus** with polished interfaces and helpful guidance

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

**Requirements**: All new features must include tests and maintain the existing test coverage.

## ğŸ“„ License

MIT License - feel free to use this project for your own AI experiments and production deployments!

---

*Built with â¤ï¸ for the AI community. Demonstrating production-ready AI system integration with enterprise-level reliability.*
